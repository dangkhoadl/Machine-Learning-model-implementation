{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset\n",
    "## 1.1 Problem\n",
    "- Translate **human language date** to a `machine standard date` format\n",
    "- Eg:\n",
    "    + **the 29th of August 1958** -> `1958-08-29`\n",
    "    + **03/30/1968**              -> `1968-03-30`\n",
    "    + **24 JUNE 1987**            -> `1987-06-24`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babel.dates import format_date\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# data generator\n",
    "fake = Faker()\n",
    "\n",
    "date_formats = ['short', 'medium', 'long',\n",
    "    'full', 'full', 'full', 'full', 'full', 'full', 'full', 'full', 'full', 'full',\n",
    "    'd MMM YYY',  'd MMMM YYY', 'dd MMM YYY', 'd MMM, YYY', 'd MMMM, YYY', 'dd, MMM YYY',\n",
    "    'd MM YY', 'd MMMM YYY', 'MMMM d YYY', 'MMMM d, YYY', 'dd.MM.YY']\n",
    "\n",
    "def generate_training_example():\n",
    "    # Get a random date (standard format)\n",
    "    machine_date = fake.date_object()\n",
    "\n",
    "    # Generate a human readable format\n",
    "    human_readable = format_date(machine_date, format=random.choice(date_formats), locale='en_US') \\\n",
    "        .lower().replace(',','')\n",
    "\n",
    "    return human_readable, machine_date.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunday june 6 2021             -> 2021-06-06\n",
      "sep 30 1971                    -> 1971-09-30\n",
      "sunday may 26 2013             -> 2013-05-26\n",
      "jul 27 1979                    -> 1979-07-27\n",
      "friday july 8 1988             -> 1988-07-08\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    human, machine = generate_training_example()\n",
    "    print(f'{human:30} -> {machine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dset(m=10000):\n",
    "    X, Y = [], []\n",
    "    for i in range(m):\n",
    "        x, y = generate_training_example()\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sunday june 13 1971', '17 june 1977', '25 05 73', '14 sep 2017', 'september 17 2003']\n",
      "['1971-06-13', '1977-06-17', '1973-05-25', '2017-09-14', '2003-09-17']\n"
     ]
    }
   ],
   "source": [
    "X, Y = generate_dset(m=10000)\n",
    "\n",
    "X_train, Y_train = X[:8000], Y[:8000]\n",
    "X_test, Y_test = X[8000:], Y[8000:]\n",
    "\n",
    "print(X_train[:5])\n",
    "print(Y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X lexicon size: 39\n",
      "{' ': 0, '.': 1, '/': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'y': 34, '<unk>': 35, '<pad>': 36, '<start>': 37, '<end>': 38}\n"
     ]
    }
   ],
   "source": [
    "X_chars = sorted(list(set(''.join(X_train)))) + ['<unk>', '<pad>', '<start>', '<end>']\n",
    "X_lexicon = { ch:idx for idx, ch in enumerate(X_chars) }\n",
    "X_lexicon_size = len(X_lexicon)\n",
    "\n",
    "print('X lexicon size:', X_lexicon_size)\n",
    "print(X_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y lexicon size: 15\n",
      "Y_lexicon = {'-': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '<unk>': 11, '<pad>': 12, '<start>': 13, '<end>': 14}\n",
      "Y_inverse_lexicon = {0: '-', 1: '0', 2: '1', 3: '2', 4: '3', 5: '4', 6: '5', 7: '6', 8: '7', 9: '8', 10: '9', 11: '<unk>', 12: '<pad>', 13: '<start>', 14: '<end>'}\n"
     ]
    }
   ],
   "source": [
    "Y_chars = sorted(list(set(''.join(Y_train)))) + ['<unk>', '<pad>', '<start>', '<end>']\n",
    "\n",
    "Y_lexicon         = { ch:idx for idx, ch in enumerate(Y_chars) }\n",
    "Y_lexicon_size    = len(Y_lexicon)\n",
    "Y_inverse_lexicon = { idx:ch for idx, ch in enumerate(Y_chars) }\n",
    "\n",
    "\n",
    "print('Y lexicon size:', Y_lexicon_size)\n",
    "print(f'{Y_lexicon = }')\n",
    "print(f'{Y_inverse_lexicon = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def get_feat_tensor(data, lexicon, pad_length=30):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        data    (list(str))         : input data list of utterances\n",
    "        lexicon (dict(char:index))  : lexicon data, categorical encoding char to int\n",
    "        pad_length (int)            : padded length of output utterance \n",
    "\n",
    "    Returns:\n",
    "        data_tensor (ndarray (m, pad_length)) : output tensor with\n",
    "            <m> training seamples\n",
    "            <pad_length> padded utterance size\n",
    "    \"\"\"\n",
    "    # one-hot encoder\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    ohe = OneHotEncoder(categories=[[idx for idx in lexicon.values()]])\n",
    "\n",
    "    # Pipeline for each utterance\n",
    "    def get_utt_tensor(utt:str):\n",
    "        # Tokenize: char to int\n",
    "        utt_tensor = [ lexicon['<start>'] ] + \\\n",
    "            [ lexicon[ch] if lexicon.get(ch) is not None\n",
    "                else lexicon['<unk>']\n",
    "                    for ch in utt ] + \\\n",
    "            [ lexicon['<end>'] ]\n",
    "\n",
    "        # padding\n",
    "        utt_tensor = utt_tensor[:pad_length]\n",
    "        if len(utt_tensor) < pad_length:\n",
    "            utt_tensor += [lexicon['<pad>']]*(pad_length - len(utt_tensor))\n",
    "\n",
    "        # Embedding: int to one-hot vector\n",
    "        utt_tensor = list(map(lambda utt: [utt], utt_tensor))\n",
    "        utt_tensor = ohe.fit_transform(utt_tensor).toarray()\n",
    "\n",
    "        return utt_tensor\n",
    "\n",
    "    # Convert m examples\n",
    "    tensor = Parallel(n_jobs=16)(delayed(function=get_utt_tensor)(utt)\n",
    "        for utt in data)\n",
    "    return np.array(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 32, 39)\n",
      "(8000, 12, 15)\n",
      "Y[0] = [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Fixed sequence length\n",
    "Tx = 32\n",
    "Ty = 12\n",
    "\n",
    "X_train_ts = get_feat_tensor(X_train, X_lexicon, pad_length=Tx)\n",
    "Y_train_ts = get_feat_tensor(Y_train, Y_lexicon, pad_length=Ty)\n",
    "\n",
    "X_test_ts = get_feat_tensor(X_test, X_lexicon, pad_length=Tx)\n",
    "Y_test_ts = get_feat_tensor(Y_test, Y_lexicon, pad_length=Ty)\n",
    "\n",
    "# X_train = (m, Tx)\n",
    "print(X_train_ts.shape)\n",
    "\n",
    "# Y_train = (m, Ty)\n",
    "print(Y_train_ts.shape)\n",
    "print('Y[0] =', Y_train_ts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, X_lexicon_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        # params\n",
    "        self.hid_feat_dim = 128\n",
    "        self.num_layers = 1\n",
    "\n",
    "         # enc\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=X_lexicon_size,\n",
    "            hidden_size=self.hid_feat_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True, dropout=0)\n",
    "\n",
    "    def forward(self, X, device='cpu'):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            X (tensor(m, Tx, X_lexicon_size))        : Input Sequence, type=Float\n",
    "                m                 : batch_size,\n",
    "                Tx                : sequence length\n",
    "                X_lexicon_size    : Input one-hot feat = X_lexicon_size\n",
    "        Returns:\n",
    "            o_enc (tensor(m, Tx, 2*hid_dim))         : Encoder output states (bi-directional)\n",
    "            h_enc (tensor(2*num_layers, m, hid_dim)) : Encoder hidden states (bi-directional)\n",
    "            c_enc (tensor(2*num_layers, m, hid_dim)) : Encoder cell states (bi-directional)\n",
    "        \"\"\"\n",
    "        # get batchsize\n",
    "        m = X.size(0)\n",
    "\n",
    "        # Init h0, c0\n",
    "        #   (2, m, hid_dim)\n",
    "        h0 = torch.zeros(2*self.num_layers, m, self.hid_feat_dim) \\\n",
    "            .float().to(device)\n",
    "        c0 = torch.zeros(2*self.num_layers, m, self.hid_feat_dim) \\\n",
    "            .float().to(device)\n",
    "\n",
    "        # Encode\n",
    "        #   o_enc: (m, Tx, 2*hid_dim)\n",
    "        #   h_enc/c_enc: (2, m, hid_dim)\n",
    "        o_enc, (h_enc, c_enc) = self.encoder(X, (h0, c0))\n",
    "        return o_enc, (h_enc, c_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_enc.size() = torch.Size([16, 32, 256])\n",
      "h_enc.size() = torch.Size([2, 16, 128]), c_enc.size() = torch.Size([2, 16, 128])\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor(X_train_ts[:16,:,:])\n",
    "\n",
    "encoder = Encoder(X_lexicon_size=39)\n",
    "o_enc, (h_enc, c_enc) = encoder(X)\n",
    "\n",
    "print(f'{o_enc.size() = }')\n",
    "print(f'{h_enc.size() = }, {c_enc.size() = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention - [https://arxiv.org/pdf/1409.0473.pdf](https://arxiv.org/pdf/1409.0473.pdf)\n",
    "\n",
    "<img src=\"./assets/seq2seq_attention.jpg\" width=\"300\"/>\n",
    "\n",
    "- Energy $e_{ij}$\n",
    "    + $[]$: concat ops\n",
    "        + $h_j$: previous decoder hidden state\n",
    "        + $s_{i-1}$: encoder output states\n",
    "    + $f()$: attention function\n",
    "\n",
    "$$e_{ij} = f( [h_j, s_{i-1}] )$$\n",
    "\n",
    "- Attention weights\n",
    "\n",
    "$$\\alpha_{ij} = \\text{softmax}(e_{ij}) = \\frac{exp(e_{ij})}{\\sum\\limits_{k=1}^{Tx}exp(e_{ik})}$$\n",
    "\n",
    "- context vector: **Tell decoder which parts of hidden state which it should pay more attention (weights) to**\n",
    "    $$c_i = \\sum\\limits_{j=1}^{Tx} \\alpha_{ij}h_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        # params\n",
    "        self.hid_feat_dim = 128\n",
    "\n",
    "        # Aggregate hidden state\n",
    "        self.agg_hidden_fc = nn.Linear(\n",
    "            in_features=2*self.hid_feat_dim,\n",
    "            out_features=self.hid_feat_dim)\n",
    "\n",
    "        # Attention function\n",
    "        self.att_fc = nn.Linear(\n",
    "            in_features=3*self.hid_feat_dim,\n",
    "            out_features=1)\n",
    "\n",
    "    def forward(self, enc_states, ht_dec):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            enc_states (tensor(m, Tx, 2*hid_dim))     : Encoder output states (bi-directional)\n",
    "            ht_dec (tensor(2*num_layers, m, hid_dim)) : Previous decoder hidden states (bi-directional)\n",
    "        Returns:\n",
    "            context_vector (tensor(m, 1, 2*hid_dim))  : Context vector\n",
    "        \"\"\"\n",
    "        # get dims: batch_size, sequence_size\n",
    "        m, Tx = enc_states.size(0), enc_states.size(1)\n",
    "\n",
    "        #### Aggregate\n",
    "        # Aggregate ht_dec (bi-directional to 1 dir)\n",
    "        #    (2, m, hid_dim) -> (m, 2*hid_dim) -> (m, hid_dim)\n",
    "        ht_dec_agg = self.agg_hidden_fc(\n",
    "            torch.cat([ht_dec[0], ht_dec[1]], dim=1))\n",
    "\n",
    "        #### Attention\n",
    "        # Reshape ht_dec\n",
    "        #    (m, hid_dim) -> (m, 1, hid_dim) -> (m, Tx, hid_dim)\n",
    "        ht_reshaped = torch.unsqueeze(ht_dec_agg, dim=1) \\\n",
    "            .repeat(1,Tx,1)\n",
    "\n",
    "        # Compute energy e_ij\n",
    "        #   (m, Tx, hid_dim) + (m, Tx, 2*hid_dim) -> (m, Tx, 3*hid_dim)\n",
    "        concat = torch.cat([ht_reshaped, enc_states], dim=2)\n",
    "        #   (m, Tx, 3*hid_dim) -> (m, Tx, 1)\n",
    "        energy = F.relu(self.att_fc(concat))\n",
    "\n",
    "        # Compute attention weights alpha_ij: (m, Tx, 1)\n",
    "        alpha = F.softmax(energy, dim=2)\n",
    "\n",
    "        # Compute context vector\n",
    "        #   (m, Tx, 1) x (m, Tx, hid_dim) -> (m, 1, 2*hid_dim)\n",
    "        context_vector = torch.einsum(\"mTk,mTn->mkn\", alpha, enc_states)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context.size() = torch.Size([16, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "attention = Attention()\n",
    "\n",
    "context = attention(\n",
    "    enc_states=o_enc,\n",
    "    ht_dec=h_enc)\n",
    "\n",
    "print(f'{context.size() = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, Y_lexicon_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # params\n",
    "        self.hid_feat_dim = 128\n",
    "        self.num_layers = 1\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=2*self.hid_feat_dim + Y_lexicon_size,\n",
    "            hidden_size=self.hid_feat_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True, dropout=0)\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            in_features=2*self.hid_feat_dim,\n",
    "            out_features=Y_lexicon_size)\n",
    "\n",
    "    def forward(self, yt_prev, context_vector, ht_dec, ct_dec):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            yt_prev (tensor(m, Y_lexicon_size))    : Output sequence at prev time step (t-1), onehot vector, onehot_dim = Y_lexicon_size\n",
    "                m : batch_size\n",
    "            context_vector (tensor(m, 1, 2*hid_dim))          : Context vector from attention mechanism\n",
    "            ht_dec, ct_dec (tensor(2*num_layers, m, hid_dim)) : Previous decoder hidden/cell states (t-1) (bi-directional)\n",
    "        Returns:\n",
    "            yt_hat (tensor(m, Y_lexicon_size))  : y_hat at timestep t, out_dim = Y_lexicon_size\n",
    "            ht_dec, ct_dec (tensor(2*num_layers, m, hid_dim)) : decoder hidden/cell states at current timestep t (bi-directional)\n",
    "        \"\"\"\n",
    "        # (m, onehot_dim) -> (m, 1, onehot_dim)\n",
    "        yt_prev = yt_prev.unsqueeze(dim=1)\n",
    "\n",
    "        # Decode\n",
    "        #   (m,1,2*hid_dim) + (m, 1, onehot_dim) -> (m,1,2*hid_dim + onehot_dim)\n",
    "        concat = torch.cat([context_vector, yt_prev], dim=2)\n",
    "        #   o_dec:         (m, 1, 2*hid_dim)\n",
    "        #   ht_dec/ct_dec: (2, m, hid_dim)\n",
    "        o_dec, (ht_dec, ct_dec) = self.decoder(concat, (ht_dec, ct_dec))\n",
    "\n",
    "        # Predict y_hat\n",
    "        #   (m, 1, 2*hid_dim) -> (m, 1, y_lexicon_dim) -> (m, y_lexicon_dim)\n",
    "        yt_hat = self.fc(o_dec).squeeze(dim=1)\n",
    "        yt_hat = F.log_softmax(yt_hat, dim=1)\n",
    "\n",
    "        return yt_hat, ht_dec, ct_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.size() = torch.Size([16, 12, 15]), y0.size() = torch.Size([16, 15])\n",
      "y1_hat.size() = torch.Size([16, 15])\n"
     ]
    }
   ],
   "source": [
    "Y = torch.Tensor(Y_train_ts[:16])\n",
    "y0 = Y[:, 0]\n",
    "print(f'{Y.size() = }, {y0.size() = }')\n",
    "\n",
    "decoder = Decoder(Y_lexicon_size=15)\n",
    "y1_hat, ht_dec, ct_dec = decoder(yt_prev=y0,\n",
    "    context_vector=context,\n",
    "    ht_dec=h_enc, ct_dec=c_enc)\n",
    "\n",
    "print(f'{y1_hat.size() = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Models\n",
    "- Apply context vector to all decoder hidden states\n",
    "\n",
    "<img src=\"./assets/seq2seq_context.png\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, X_lexicon_size, Y_lexicon_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(X_lexicon_size=X_lexicon_size)\n",
    "        self.attention = Attention()\n",
    "        self.decoder = Decoder(Y_lexicon_size=Y_lexicon_size)\n",
    "\n",
    "    def forward(self, X, Y,\n",
    "            device='cpu', teacher_force_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            X (Long tensor(m, Tx, X_lexicon_size))        : Input sequence\n",
    "            Y (Long tensor(m, Ty, Y_lexicon_size))        : Output sequence\n",
    "            teacher_force_ratio (float)   : teaching forcing probability in range [0,1]\n",
    "        Returns:\n",
    "            Y_hat (tensor(m, Ty, Y_lexicon_size)) : Y_hat, out_dim = Y_lexicon_size\n",
    "        \"\"\"\n",
    "        # Get dim\n",
    "        m, Ty, Y_lexicon_size = Y.size()\n",
    "\n",
    "        # Encode\n",
    "        enc_out, (h_enc, c_enc) = self.encoder(X, device=device)\n",
    "\n",
    "        # Init yt_prev = <start>, (m, Y_lexicon_size)\n",
    "        yt_prev = Y[:, 0]\n",
    "\n",
    "        # Init h_dec, c_dec\n",
    "        ht_dec, ct_dec = h_enc, c_enc\n",
    "\n",
    "        # Predict next timestep\n",
    "        Y_hat = torch.zeros(m, Ty, Y_lexicon_size).to(device)\n",
    "        for t in range(1, Ty):\n",
    "            # Attention\n",
    "            context = self.attention(\n",
    "                enc_states=enc_out,\n",
    "                ht_dec=ht_dec)\n",
    "\n",
    "            # Decode\n",
    "            Y_hat[:,t,:] , ht_dec, ct_dec = self.decoder(\n",
    "                yt_prev=yt_prev,\n",
    "                context_vector=context,\n",
    "                ht_dec=ht_dec, ct_dec=ct_dec)\n",
    "\n",
    "            # Teaching forcing:\n",
    "            #   prob:      Force yt_prev = Y[t+1]\n",
    "            #   1 - prob:  get prediction from model\n",
    "            if random.random() < teacher_force_ratio:\n",
    "                yt_prev = Y[:,t,:]\n",
    "            else:\n",
    "                yt_prev = Y_hat[:,t,:]\n",
    "\n",
    "        return Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_hat.size() = torch.Size([16, 12, 15])\n"
     ]
    }
   ],
   "source": [
    "net = Seq2Seq(X_lexicon_size=39, Y_lexicon_size=15)\n",
    "Y_hat = net(X, Y)\n",
    "\n",
    "print(f'{Y_hat.size() = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fit(\n",
    "        X, Y,\n",
    "        alpha=1e-2, num_iters=1000, batch_size=16, teacher_force_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X (ndarray(m, Tx, X_lexicon_size))  : Input sequence\n",
    "        Y (ndarray(m, Ty, Y_lexicon_size))  : Output sequence\n",
    "    Returns:\n",
    "        net (torch model)       : trained seq2seq model\n",
    "        J_history (list)        : List of cost each iter for plotting\n",
    "    \"\"\"\n",
    "    # Params\n",
    "    X_lexicon_size = X.shape[2]\n",
    "    Y_lexicon_size = Y.shape[2]\n",
    "\n",
    "    # Dataset\n",
    "    dset = TensorDataset(\n",
    "        torch.Tensor(X),\n",
    "        torch.Tensor(Y))\n",
    "\n",
    "    # Dataloader\n",
    "    dloader = DataLoader(\n",
    "        dataset=dset,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    ## Config\n",
    "    device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Model\n",
    "    net = Seq2Seq(\n",
    "        X_lexicon_size=X_lexicon_size,\n",
    "        Y_lexicon_size=Y_lexicon_size)\n",
    "    net = net.to(device)\n",
    "    net.train()\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=alpha)\n",
    "\n",
    "    # cost and params history\n",
    "    J_history = []\n",
    "    for i in range(num_iters):\n",
    "        cost = 0\n",
    "        for b, batch in enumerate(dloader):\n",
    "            # Batch:\n",
    "            #    X_b = (batch_size, Tx, X_lexicon_size)\n",
    "            #    Y_b = (batch_size, Ty, Y_lexicon_size)\n",
    "            Xb, Yb = batch\n",
    "            Xb = Xb.to(device).to(torch.float32)\n",
    "            Yb = Yb.to(device).to(torch.float32)\n",
    "\n",
    "            # Forward\n",
    "            #    Yb_hat = (batch_size, Ty, Y_lexicon_size)\n",
    "            optimizer.zero_grad()\n",
    "            Yb_hat = net(Xb, Yb,\n",
    "                device=device, teacher_force_ratio=teacher_force_ratio)\n",
    "\n",
    "            # Batch Cost compute, t=1 skip <start>\n",
    "            Yb_hat_reshaped = Yb_hat[:,1:,:].reshape(-1, Y_lexicon_size)\n",
    "            Yb_reshaped = Yb[:,1:].argmax(dim=2).reshape(-1)\n",
    "\n",
    "            cost_b = criterion(Yb_hat_reshaped, Yb_reshaped)\n",
    "\n",
    "            # Track Iter Cost\n",
    "            cost += cost_b.item()\n",
    "\n",
    "            # Back Propagation\n",
    "            cost_b.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clip grad to avoid exploding gradient\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), max_norm=1)\n",
    "\n",
    "        # Compute Cost\n",
    "        J_history.append(cost)\n",
    "        if i % 10 == 0 or i == num_iters-1:\n",
    "            print(f\"Cost after iteration {i:4}: {cost:.4f}\")\n",
    "    return net, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tx = 32, X_lexicon_size = 39\n",
      "Ty = 12, Y_lexicon_size = 15\n",
      "Cost after iteration    0: 70.4859\n",
      "Cost after iteration   10: 17.7201\n",
      "Cost after iteration   20: 4.6069\n",
      "Cost after iteration   30: 1.8351\n",
      "Cost after iteration   40: 0.5370\n",
      "Cost after iteration   50: 0.2569\n",
      "Cost after iteration   60: 0.1357\n",
      "Cost after iteration   70: 0.0861\n",
      "Cost after iteration   80: 0.0645\n",
      "Cost after iteration   90: 0.0360\n",
      "Cost after iteration   99: 0.0273\n"
     ]
    }
   ],
   "source": [
    "print(f'{Tx = }, {X_lexicon_size = }')\n",
    "print(f'{Ty = }, {Y_lexicon_size = }')\n",
    "\n",
    "model, J_hist = fit(\n",
    "    X=X_train_ts, Y=Y_train_ts,\n",
    "    alpha=1e-3, num_iters=100, batch_size=256,\n",
    "    teacher_force_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12,4))\n",
    "\n",
    "ax1.plot(J_hist[:10])\n",
    "ax2.plot(10 + np.arange(len(J_hist[10:])), J_hist[10:])\n",
    "ax1.set_title(\"Cost vs. iteration(start)\");  ax2.set_title(\"Cost vs. iteration (end)\")\n",
    "ax1.set_ylabel('Cost')            ;  ax2.set_ylabel('Cost')\n",
    "ax1.set_xlabel('iteration step')  ;  ax2.set_xlabel('iteration step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, input_sentence,\n",
    "          X_lexicon, Y_inverse_lexicon,\n",
    "          Tx=32, Ty=12):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        model (torch model)                 : trained seq2seq model\n",
    "        input_sentence (str)                : Input human readable format\n",
    "        X_lexicon (dict(ch:idx))            : Human dictionary\n",
    "        Y_inverse_lexicon (dict(idx:ch))    : Machine inverse dictionary\n",
    "    Returns:\n",
    "        output_sentence (str)               : Predicted machine readable format from model\n",
    "    \"\"\"\n",
    "    Y_lexicon_size = len(Y_inverse_lexicon)\n",
    "\n",
    "    model.cpu()\n",
    "    with torch.no_grad():\n",
    "        # str -> [37,2,1,56,38] -> tensor(1, Tx, X_lexicon_size)\n",
    "        X_tensor = torch.Tensor(\n",
    "            get_feat_tensor([input_sentence], X_lexicon, pad_length=Tx))\n",
    "        m = X_tensor.size(0) # m = 1\n",
    "\n",
    "        # infer: Y_hat = (1, Ty, Y_lexicon_size)\n",
    "        m = X_tensor.size(0)\n",
    "        Y_dummy = torch.zeros(m, Ty, Y_lexicon_size).to(torch.int64)\n",
    "        Y_hat = model(X_tensor, Y_dummy,\n",
    "            device='cpu', teacher_force_ratio=0)\n",
    "\n",
    "        # predict\n",
    "        output_sentence = ''\n",
    "\n",
    "        # (1, Ty, Y_lexicon_size) -> (1, Ty) -> (Ty)\n",
    "        y_seq = torch.argmax(Y_hat, dim=2).squeeze(dim=0)\n",
    "        y_seq = y_seq.numpy().tolist()\n",
    "\n",
    "        # skip <start>\n",
    "        for idx in y_seq[1:]:\n",
    "            if Y_inverse_lexicon[idx] == '<end>': break\n",
    "            output_sentence += Y_inverse_lexicon[idx]\n",
    "        return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Input]                        [Prediction]    [Correct Label]\n",
      "friday november 28 1997        1997-11-28      1997-11-28     \n",
      "thursday march 3 1994          1994-03-03      1994-03-03     \n",
      "10 jun 2011                    2011-06-10      2011-06-10     \n",
      "tuesday may 20 1997            1997-05-20      1997-05-20     \n",
      "september 9 1985               1985-09-09      1985-09-09     \n",
      "9 january 1980                 1980-01-09      1980-01-09     \n",
      "june 3 2003                    2003-06-03      2003-06-03     \n",
      "monday november 12 1984        1984-11-12      1984-11-12     \n",
      "6 february 2017                2017-02-06      2017-02-06     \n",
      "06.04.03                       2003-04-06      2003-04-06     \n"
     ]
    }
   ],
   "source": [
    "print(f'{\"[Input]\":30} {\"[Prediction]\":15} {\"[Correct Label]\":15}')\n",
    "for i in range(10):\n",
    "    pred = infer(model, X_test[i],\n",
    "        X_lexicon=X_lexicon, Y_inverse_lexicon=Y_inverse_lexicon,\n",
    "        Tx=Tx, Ty=Ty)\n",
    "    print(f'{X_test[i]:30} {pred:15} {Y_test[i]:15}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 98.400%\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "Y_test_pred = Parallel(n_jobs=16)(delayed(function=infer)(model, utt,\n",
    "    X_lexicon=X_lexicon, Y_inverse_lexicon=Y_inverse_lexicon,\n",
    "    Tx=Tx, Ty=Ty)\n",
    "        for utt in X_test)\n",
    "\n",
    "# Acc\n",
    "scores = [ 1 if Y_test_pred[i] == Y_test[i] else 0 \\\n",
    "    for i in range(len(Y_test)) ]\n",
    "print(f'Test accuracy = {100.0*sum(scores)/len(Y_test):.3f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b166c11a6fb13fc284d60599e45a47824480cbed14934159809ec834d0d5166e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
