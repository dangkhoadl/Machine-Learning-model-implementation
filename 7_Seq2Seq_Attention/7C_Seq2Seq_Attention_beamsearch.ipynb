{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset\n",
    "## 1.1 Problem\n",
    "- Translate **human language date** to a `machine standard date` format\n",
    "- Eg:\n",
    "    + **the 29th of August 1958** -> `1958-08-29`\n",
    "    + **03/30/1968**              -> `1968-03-30`\n",
    "    + **24 JUNE 1987**            -> `1987-06-24`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babel.dates import format_date\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# data generator\n",
    "fake = Faker()\n",
    "\n",
    "date_formats = ['short', 'medium', 'long',\n",
    "    'full', 'full', 'full', 'full', 'full', 'full', 'full', 'full', 'full', 'full',\n",
    "    'd MMM YYY',  'd MMMM YYY', 'dd MMM YYY', 'd MMM, YYY', 'd MMMM, YYY', 'dd, MMM YYY',\n",
    "    'd MM YY', 'd MMMM YYY', 'MMMM d YYY', 'MMMM d, YYY', 'dd.MM.YY']\n",
    "\n",
    "def generate_training_example():\n",
    "    # Get a random date (standard format)\n",
    "    machine_date = fake.date_object()\n",
    "    \n",
    "    # Generate a human readable format\n",
    "    human_readable = format_date(machine_date, format=random.choice(date_formats), locale='en_US') \\\n",
    "        .lower().replace(',','')\n",
    "    \n",
    "    return human_readable, machine_date.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.09.78                       -> 1978-09-16\n",
      "monday june 30 1980            -> 1980-06-30\n",
      "friday january 15 2016         -> 2016-01-15\n",
      "18 jun 1977                    -> 1977-06-18\n",
      "tuesday january 30 2001        -> 2001-01-30\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    human, machine = generate_training_example()\n",
    "    print(f'{human:30} -> {machine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dset(m=10000):\n",
    "    X, Y = [], []\n",
    "    for i in range(m):\n",
    "        x, y = generate_training_example()\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9 april 1994', 'monday november 29 1971', '5 february 1976', 'tuesday november 30 2021', 'saturday may 29 2010']\n",
      "['1994-04-09', '1971-11-29', '1976-02-05', '2021-11-30', '2010-05-29']\n"
     ]
    }
   ],
   "source": [
    "X, Y = generate_dset(m=10000)\n",
    "\n",
    "X_train, Y_train = X[:8000], Y[:8000]\n",
    "X_test, Y_test = X[8000:], Y[8000:]\n",
    "\n",
    "print(X_train[:5])\n",
    "print(Y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X lexicon size: 39\n",
      "{' ': 0, '.': 1, '/': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'y': 34, '<unk>': 35, '<pad>': 36, '<start>': 37, '<end>': 38}\n"
     ]
    }
   ],
   "source": [
    "X_chars = sorted(list(set(''.join(X_train)))) + ['<unk>', '<pad>', '<start>', '<end>']\n",
    "X_lexicon = { ch:idx for idx, ch in enumerate(X_chars) }\n",
    "X_lexicon_size = len(X_lexicon)\n",
    "\n",
    "print('X lexicon size:', X_lexicon_size)\n",
    "print(X_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y lexicon size: 15\n",
      "Y_lexicon = {'-': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '<unk>': 11, '<pad>': 12, '<start>': 13, '<end>': 14}\n",
      "Y_inverse_lexicon = {0: '-', 1: '0', 2: '1', 3: '2', 4: '3', 5: '4', 6: '5', 7: '6', 8: '7', 9: '8', 10: '9', 11: '<unk>', 12: '<pad>', 13: '<start>', 14: '<end>'}\n"
     ]
    }
   ],
   "source": [
    "Y_chars = sorted(list(set(''.join(Y_train)))) + ['<unk>', '<pad>', '<start>', '<end>']\n",
    "\n",
    "Y_lexicon         = { ch:idx for idx, ch in enumerate(Y_chars) }\n",
    "Y_lexicon_size    = len(Y_lexicon)\n",
    "Y_inverse_lexicon = { idx:ch for idx, ch in enumerate(Y_chars) }\n",
    "\n",
    "\n",
    "print('Y lexicon size:', Y_lexicon_size)\n",
    "print(f'{Y_lexicon = }')\n",
    "print(f'{Y_inverse_lexicon = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def get_feat_tensor(data, lexicon, pad_length=30):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        data    (list(str))         : input data list of utterances\n",
    "        lexicon (dict(char:index))  : lexicon data, categorical encoding char to int\n",
    "        pad_length (int)            : padded length of output utterance \n",
    "\n",
    "    Returns:\n",
    "        data_tensor (ndarray (m, pad_length)) : output tensor with\n",
    "            <m> training seamples\n",
    "            <pad_length> padded utterance size\n",
    "    \"\"\"\n",
    "\n",
    "    # Pipeline for each utterance\n",
    "    def get_utt_tensor(utt:str):\n",
    "        # Tokenize: char to int\n",
    "        utt_tensor = [ lexicon['<start>'] ] + \\\n",
    "            [ lexicon[ch] if lexicon.get(ch) is not None\n",
    "                else lexicon['<unk>']\n",
    "                    for ch in utt ] + \\\n",
    "            [ lexicon['<end>'] ]\n",
    "\n",
    "        # padding\n",
    "        utt_tensor = utt_tensor[:pad_length]\n",
    "        if len(utt_tensor) < pad_length:\n",
    "            utt_tensor += [lexicon['<pad>']]*(pad_length - len(utt_tensor))\n",
    "\n",
    "        return np.array(utt_tensor)\n",
    "\n",
    "    # Convert m examples\n",
    "    tensor = Parallel(n_jobs=16)(delayed(function=get_utt_tensor)(utt)\n",
    "        for utt in data)\n",
    "    return np.array(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_ts.shape = (8000, 32)\n",
      "X[0] = [37 12  0 13 27 28 21 23  0  4 12 12  7 38 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36 36 36]\n",
      "\n",
      "Y_train_ts.shape = (8000, 17)\n",
      "Y[0] = [13  2 10 10  5  0  1  5  0  1 10 14 12 12 12 12 12]\n"
     ]
    }
   ],
   "source": [
    "# Fixed sequence length\n",
    "Tx = 32\n",
    "Ty = 17\n",
    "\n",
    "X_train_ts = get_feat_tensor(X_train, X_lexicon, pad_length=Tx)\n",
    "Y_train_ts = get_feat_tensor(Y_train, Y_lexicon, pad_length=Ty)\n",
    "\n",
    "X_test_ts = get_feat_tensor(X_test, X_lexicon, pad_length=Tx)\n",
    "Y_test_ts = get_feat_tensor(Y_test, Y_lexicon, pad_length=Ty)\n",
    "\n",
    "# X_train = (m, Tx)\n",
    "print(f'{X_train_ts.shape = }')\n",
    "print('X[0] =', X_train_ts[0], end='\\n\\n')\n",
    "\n",
    "# Y_train = (m, Ty)\n",
    "print(f'{Y_train_ts.shape = }')\n",
    "print('Y[0] =', Y_train_ts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, X_lexicon_size):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # params\n",
    "        self.emb_dim = 64\n",
    "        self.hid_feat_dim = 128\n",
    "        self.num_layers = 1\n",
    "        \n",
    "        # Emb\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=X_lexicon_size,\n",
    "            embedding_dim=self.emb_dim)\n",
    "\n",
    "        # enc\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=self.emb_dim,\n",
    "            hidden_size=self.hid_feat_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True, dropout=0)\n",
    "\n",
    "    def forward(self, X, device='cpu'):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            X (Longtensor(m, Tx))                : Input Sequence, type=Long\n",
    "                m: batch_size,\n",
    "                Tx: sequence length \n",
    "        Returns:\n",
    "            o_enc (tensor(m, Tx, 2*hid_dim))         : Encoder output states (bi-directional)\n",
    "            h_enc (tensor(2*num_layers, m, hid_dim)) : Encoder hidden states (bi-directional)\n",
    "            c_enc (tensor(2*num_layers, m, hid_dim)) : Encoder cell states (bi-directional)\n",
    "        \"\"\"\n",
    "        # get batchsize\n",
    "        m = X.size(0)\n",
    "\n",
    "        # Embedding\n",
    "        #    (m, Tx) -> (m, Tx, emb_dim)\n",
    "        emb = self.embedding(X)\n",
    "        emb = F.relu(emb)\n",
    "    \n",
    "        # Init h0, c0\n",
    "        #   (2, m, hid_dim)\n",
    "        h0 = torch.zeros(2*self.num_layers, m, self.hid_feat_dim) \\\n",
    "            .float().to(device)\n",
    "        c0 = torch.zeros(2*self.num_layers, m, self.hid_feat_dim) \\\n",
    "            .float().to(device)\n",
    "\n",
    "        # Encode\n",
    "        #   o_enc: (m, Tx, 2*hid_dim)\n",
    "        #   h_enc/c_enc: (2, m, hid_dim)\n",
    "        o_enc, (h_enc, c_enc) = self.encoder(emb, (h0, c0))\n",
    "        return o_enc, (h_enc, c_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_enc.size() = torch.Size([16, 32, 256])\n",
      "h_enc.size() = torch.Size([2, 16, 128]), c_enc.size() = torch.Size([2, 16, 128])\n"
     ]
    }
   ],
   "source": [
    "X = torch.LongTensor(X_train_ts[:16])\n",
    "\n",
    "encoder = Encoder(X_lexicon_size=39)\n",
    "o_enc, (h_enc, c_enc) = encoder(X)\n",
    "\n",
    "print(f'{o_enc.size() = }')\n",
    "print(f'{h_enc.size() = }, {c_enc.size() = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention - [https://arxiv.org/pdf/1409.0473.pdf](https://arxiv.org/pdf/1409.0473.pdf)\n",
    "\n",
    "<img src=\"./assets/seq2seq_attention.jpg\" width=\"300\"/>\n",
    "\n",
    "- Energy $e_{ij}$\n",
    "    + $[]$: concat ops\n",
    "        + $h_j$: previous decoder hidden state\n",
    "        + $s_{i-1}$: encoder output states\n",
    "    + $f()$: attention function\n",
    "  \n",
    "$$e_{ij} = f( [h_j, s_{i-1}] )$$\n",
    "\n",
    "- Attention (weights)\n",
    "\n",
    "$$\\alpha_{ij} = \\text{softmax}(e_{ij}) = \\frac{exp(e_{ij})}{\\sum\\limits_{k=1}^{Tx}exp(e_{ik})}$$\n",
    "\n",
    "- context vector: **Tell decoder which parts of hidden state which it should pay more attention (weights) to**\n",
    "    $$c_i = \\sum\\limits_{j=1}^{Tx} \\alpha_{ij}h_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        # params\n",
    "        self.hid_feat_dim = 128\n",
    "\n",
    "        # Aggregate hidden state\n",
    "        self.agg_hidden_fc = nn.Linear(\n",
    "            in_features=2*self.hid_feat_dim,\n",
    "            out_features=self.hid_feat_dim)\n",
    "\n",
    "        # Attention function\n",
    "        self.att_fc = nn.Linear(\n",
    "            in_features=3*self.hid_feat_dim,\n",
    "            out_features=1)\n",
    "\n",
    "    def forward(self, enc_states, ht_dec):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            enc_states (tensor(m, Tx, 2*hid_dim))     : Encoder output states (bi-directional)\n",
    "            ht_dec (tensor(2*num_layers, m, hid_dim)) : Previous decoder hidden states (bi-directional)\n",
    "        Returns:\n",
    "            context_vector (tensor(m, 1, 2*hid_dim))  : Context vector\n",
    "        \"\"\"\n",
    "        # get dims: batch_size, sequence_size\n",
    "        m, Tx = enc_states.size(0), enc_states.size(1)\n",
    "\n",
    "        #### Aggregate\n",
    "        # Aggregate ht_dec (bi-directional to 1 dir)\n",
    "        #    (2, m, hid_dim) -> (m, 2*hid_dim) -> (m, hid_dim) \n",
    "        ht_dec_agg = self.agg_hidden_fc(\n",
    "            torch.cat([ht_dec[0], ht_dec[1]], dim=1))\n",
    "\n",
    "        #### Attention\n",
    "        # Reshape ht_dec\n",
    "        #    (m, hid_dim) -> (m, 1, hid_dim) -> (m, Tx, hid_dim) \n",
    "        ht_reshaped = torch.unsqueeze(ht_dec_agg, dim=1) \\\n",
    "            .repeat(1,Tx,1)\n",
    "\n",
    "        # Compute energy e_ij\n",
    "        #   (m, Tx, hid_dim) + (m, Tx, 2*hid_dim) -> (m, Tx, 3*hid_dim)\n",
    "        concat = torch.cat([ht_reshaped, enc_states], dim=2)\n",
    "        #   (m, Tx, 3*hid_dim) -> (m, Tx, 1)\n",
    "        energy = F.relu(self.att_fc(concat))\n",
    "\n",
    "        # Compute attention alpha_ij: (m, Tx, 1)\n",
    "        alpha = F.softmax(energy, dim=2)\n",
    "\n",
    "        # Compute context vector\n",
    "        #   (m, Tx, 1) x (m, Tx, hid_dim) -> (m, 1, 2*hid_dim)\n",
    "        context_vector = torch.einsum(\"mTk,mTn->mkn\", alpha, enc_states)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context.size() = torch.Size([16, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "attention = Attention()\n",
    "\n",
    "context = attention(\n",
    "    enc_states=o_enc,\n",
    "    ht_dec=h_enc)\n",
    "\n",
    "print(f'{context.size() = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, Y_lexicon_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # params\n",
    "        self.emb_dim = 64\n",
    "        self.hid_feat_dim = 128\n",
    "        self.num_layers = 1\n",
    "\n",
    "        # Emb\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=Y_lexicon_size,\n",
    "            embedding_dim=self.emb_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=2*self.hid_feat_dim + self.emb_dim,\n",
    "            hidden_size=self.hid_feat_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True, dropout=0)\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            in_features=2*self.hid_feat_dim,\n",
    "            out_features=Y_lexicon_size)\n",
    "\n",
    "    def forward(self, yt_prev, context_vector, ht_dec, ct_dec):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            yt_prev (Long tensor(m))  : Output sequence at prev time step (t-1), categorical Long\n",
    "                m: batchsize\n",
    "            context_vector (tensor(m, 1, 2*hid_dim))          : Context vector from attention mechanism\n",
    "            ht_dec, ct_dec (tensor(2*num_layers, m, hid_dim)) : Previous decoder hidden/cell states (t-1) (bi-directional)\n",
    "        Returns:\n",
    "            yt_hat (tensor(m, Y_lexicon_size))                : y_hat at timestep t, out_dim = Y_lexicon_size\n",
    "            ht_dec, ct_dec (tensor(2*num_layers, m, hid_dim)) : decoder hidden/cell states at current timestep t (bi-directional)\n",
    "        \"\"\"\n",
    "        # (m) -> (m, 1)\n",
    "        yt_prev = yt_prev.unsqueeze(dim=1)\n",
    "\n",
    "        # Embedding\n",
    "        #    (m, 1) -> (m, 1, emb_dim)\n",
    "        emb = self.embedding(yt_prev)\n",
    "        emb = F.relu(emb)\n",
    "\n",
    "        # Decode\n",
    "        #   (m,1,2*hid_dim) + (m,1,emb_dim) -> (m,1,2*hid_dim + emb_dim)\n",
    "        concat = torch.cat([context_vector, emb], dim=2)\n",
    "        #   o_dec:         (m, 1, 2*hid_dim)\n",
    "        #   ht_dec/ct_dec: (2, m, hid_dim)\n",
    "        o_dec, (ht_dec, ct_dec) = self.decoder(concat, (ht_dec, ct_dec))\n",
    "\n",
    "        # Predict y_hat\n",
    "        #   (m, 1, 2*hid_dim) -> (m, 1, y_lexicon_dim) -> (m, y_lexicon_dim)\n",
    "        yt_hat = self.fc(o_dec).squeeze(dim=1)\n",
    "        yt_hat = F.log_softmax(yt_hat, dim=1)\n",
    "\n",
    "        return yt_hat, ht_dec, ct_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.size() = torch.Size([16, 17]), y0.size() = torch.Size([16])\n",
      "y1_hat.size() = torch.Size([16, 15])\n"
     ]
    }
   ],
   "source": [
    "Y = torch.LongTensor(Y_train_ts[:16])\n",
    "y0 = Y[:, 0]\n",
    "print(f'{Y.size() = }, {y0.size() = }')\n",
    "\n",
    "decoder = Decoder(Y_lexicon_size=15)\n",
    "y1_hat, ht_dec, ct_dec = decoder(yt_prev=y0,\n",
    "    context_vector=context,\n",
    "    ht_dec=h_enc, ct_dec=c_enc)\n",
    "\n",
    "print(f'{y1_hat.size() = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def train_seq2seq(X, Y,\n",
    "        encoder, attention, decoder,\n",
    "        Y_lexicon_size,\n",
    "        device='cpu', teacher_force_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X (Long tensor(m, Tx))                      : Input sequence\n",
    "        Y (Long tensor(m, Ty))                      : Output sequence\n",
    "        encoder, attention, decoder (torch.model)   : training models\n",
    "        Y_lexicon_size (int)                        : Output sequence feat_dim = size of vocab Y\n",
    "        teacher_force_ratio (float)   : teaching forcing probability in range [0,1]\n",
    "    Returns:\n",
    "        Y_hat (tensor(m, Ty, Y_lexicon_size)): Y_hat, out_dim = Y_lexicon_size\n",
    "    \"\"\"\n",
    "    # Get dim\n",
    "    m, Ty = Y.size(0), Y.size(1)\n",
    "\n",
    "    # Encode\n",
    "    enc_out, (h_enc, c_enc) = encoder(X, device=device)\n",
    "\n",
    "    # Init yt_prev = <start>, long tensor (m,)\n",
    "    yt_prev = Y[:, 0]\n",
    "\n",
    "    # Init h_dec, c_dec\n",
    "    ht_dec, ct_dec = h_enc, c_enc\n",
    "\n",
    "    # Predict next timestep\n",
    "    Y_hat = torch.zeros(m, Ty, Y_lexicon_size).to(device)\n",
    "    for t in range(1, Ty):\n",
    "        # Attention\n",
    "        context = attention(\n",
    "            enc_states=enc_out,\n",
    "            ht_dec=ht_dec)\n",
    "\n",
    "        # Decode\n",
    "        Y_hat[:,t,:] , ht_dec, ct_dec = decoder(\n",
    "            yt_prev=yt_prev,\n",
    "            context_vector=context,\n",
    "            ht_dec=ht_dec, ct_dec=ct_dec)\n",
    "\n",
    "        # Teaching forcing:\n",
    "        #   prob:      Force yt_prev = Y[t+1]\n",
    "        #   1 - prob:  get prediction from model\n",
    "        if random.random() < teacher_force_ratio:\n",
    "            yt_prev = Y[:,t]\n",
    "        else:\n",
    "            yt_prev = Y_hat[:,t,:].argmax(dim=1)\n",
    "\n",
    "    return Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fit(\n",
    "        X, Y,\n",
    "        X_lexicon_size, Y_lexicon_size, Y_pad_token,\n",
    "        alpha=1e-2, num_iters=1000, batch_size=16, teacher_force_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X (ndarray(m, Tx))      : Input sequence\n",
    "        Y (ndarray(m, Ty))      : Output sequence\n",
    "        X_lexicon_size (int)    : Input sequence feat_dim = size of vocab X.\n",
    "        Y_lexicon_size (int)    : Output sequence feat_dim = size of vocab Y.\n",
    "        Y_pad_token (int)       : Padding token of target sequence, ignore when computing cost\n",
    "    Returns:\n",
    "        encoder (torch model)       : trained encoder\n",
    "        attention (torch model)     : trained attention\n",
    "        decoder (torch model)       : trained decoder\n",
    "        J_history (list)            : List of cost each iter for plotting\n",
    "    \"\"\"\n",
    "    # Dataset\n",
    "    dset = TensorDataset(\n",
    "        torch.LongTensor(X),\n",
    "        torch.LongTensor(Y))\n",
    "\n",
    "    # Dataloader\n",
    "    dloader = DataLoader(\n",
    "        dataset=dset,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    ## Config\n",
    "    device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Model\n",
    "    encoder = Encoder(X_lexicon_size=X_lexicon_size)\n",
    "    encoder = encoder.to(device)\n",
    "    encoder.train()\n",
    "\n",
    "    attention = Attention()\n",
    "    attention = attention.to(device)\n",
    "    attention.train()\n",
    "\n",
    "    decoder = Decoder(Y_lexicon_size=Y_lexicon_size)\n",
    "    decoder = decoder.to(device)\n",
    "    decoder.train()\n",
    "    \n",
    "\n",
    "    # Criterions\n",
    "    #    Note: Exclude padding token when compte loss\n",
    "    criterion = nn.NLLLoss(\n",
    "        ignore_index=Y_pad_token)\n",
    "    encoder_opt = torch.optim.Adam(encoder.parameters(), lr=alpha)\n",
    "    attention_opt = torch.optim.Adam(attention.parameters(), lr=alpha)\n",
    "    decoder_opt = torch.optim.Adam(decoder.parameters(), lr=alpha)\n",
    "\n",
    "    # cost and params history\n",
    "    J_history = []\n",
    "    for i in range(num_iters):\n",
    "        cost = 0\n",
    "        for b, batch in enumerate(dloader):\n",
    "            # Batch:\n",
    "            #    X_b = (batch_size, Tx)\n",
    "            #    Y_b = (batch_size, Ty)\n",
    "            Xb, Yb = batch\n",
    "            Xb = Xb.to(device).to(torch.int64)\n",
    "            Yb = Yb.to(device).to(torch.int64)\n",
    "\n",
    "            # Forward\n",
    "            #    Yb_hat = (batch_size, Ty, Y_lexicon_size)\n",
    "            encoder_opt.zero_grad()\n",
    "            attention_opt.zero_grad()\n",
    "            decoder_opt.zero_grad()\n",
    "\n",
    "            Yb_hat = train_seq2seq(Xb, Yb,\n",
    "                encoder=encoder, attention=attention, decoder=decoder,\n",
    "                Y_lexicon_size=Y_lexicon_size,\n",
    "                device=device, teacher_force_ratio=0.5)\n",
    "\n",
    "            # Batch Cost compute, t=1 skip <start>\n",
    "            Yb_hat_reshaped = Yb_hat[:,1:,:].reshape(-1, Y_lexicon_size)\n",
    "            Yb_reshaped = Yb[:,1:].reshape(-1)\n",
    "\n",
    "            cost_b = criterion(Yb_hat_reshaped, Yb_reshaped)\n",
    "\n",
    "            # Track Iter Cost\n",
    "            cost += cost_b.item()\n",
    "\n",
    "            # Back Propagation\n",
    "            cost_b.backward()\n",
    "            encoder_opt.step()\n",
    "            attention_opt.step()\n",
    "            decoder_opt.step()\n",
    "\n",
    "            # Clip grad to avoid exploding gradient\n",
    "            nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
    "            nn.utils.clip_grad_norm_(attention.parameters(), max_norm=1)\n",
    "            nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
    "\n",
    "        # Compute Cost\n",
    "        J_history.append(cost)\n",
    "        if i % 10 == 0 or i == num_iters-1:\n",
    "            print(f\"Cost after iteration {i:4}: {cost:.4f}\")\n",
    "    return (encoder, attention, decoder), J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tx = 32, X_lexicon_size = 39\n",
      "Ty = 17, Y_lexicon_size = 15\n",
      "Cost after iteration    0: 67.1989\n",
      "Cost after iteration   10: 6.9798\n",
      "Cost after iteration   20: 1.1946\n",
      "Cost after iteration   30: 0.2911\n",
      "Cost after iteration   40: 0.1139\n",
      "Cost after iteration   50: 0.0596\n",
      "Cost after iteration   60: 0.0325\n",
      "Cost after iteration   70: 0.0201\n",
      "Cost after iteration   80: 0.0137\n",
      "Cost after iteration   90: 0.0096\n",
      "Cost after iteration  100: 0.0071\n",
      "Cost after iteration  110: 0.0054\n",
      "Cost after iteration  119: 0.0042\n"
     ]
    }
   ],
   "source": [
    "print(f'{Tx = }, {X_lexicon_size = }')\n",
    "print(f'{Ty = }, {Y_lexicon_size = }')\n",
    "\n",
    "model, J_hist = fit(\n",
    "    X=X_train_ts, Y=Y_train_ts,\n",
    "    X_lexicon_size=X_lexicon_size,\n",
    "    Y_lexicon_size=Y_lexicon_size, Y_pad_token=Y_lexicon['<pad>'],\n",
    "    alpha=1e-3, num_iters=120, batch_size=256,\n",
    "    teacher_force_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12,4))\n",
    "\n",
    "ax1.plot(J_hist[:10])\n",
    "ax2.plot(10 + np.arange(len(J_hist[10:])), J_hist[10:])\n",
    "ax1.set_title(\"Cost vs. iteration(start)\");  ax2.set_title(\"Cost vs. iteration (end)\")\n",
    "ax1.set_ylabel('Cost')            ;  ax2.set_ylabel('Cost')\n",
    "ax1.set_xlabel('iteration step')  ;  ax2.set_xlabel('iteration step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer - beamsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def infer_beam(model, input_sentence,\n",
    "        X_lexicon,\n",
    "        Y_lexicon, Y_inverse_lexicon,\n",
    "        Tx=32, Ty=12, beam_width=5):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        model (tuple of torch models)       : trained seq2seq model (encoder, attention, decoder)\n",
    "        input_sentence (str)                : Input human readable format\n",
    "        X_lexicon (dict(ch:idx))            : Human dictionary\n",
    "        Y_lexicon (dict(ch:idx))            : Machine dictionary\n",
    "        Y_inverse_lexicon (dict(idx:ch))    : Machine inverse dictionary\n",
    "    Returns:\n",
    "        output_sentence (str)               : Predicted machine readable format from model\n",
    "    \"\"\"\n",
    "    (encoder, attention, decoder) = model\n",
    "    encoder.cpu()   ; encoder.eval()\n",
    "    attention.cpu() ; attention.eval()\n",
    "    decoder.cpu()   ; decoder.eval()\n",
    "    \n",
    "    # str -> [37,2,1,56,38] -> tensor(1, Tx)\n",
    "    X_seq = torch.LongTensor(\n",
    "        get_feat_tensor([input_sentence], X_lexicon, pad_length=Tx))\n",
    "\n",
    "    # Encode X\n",
    "    with torch.no_grad():\n",
    "        enc_out, (h_enc, c_enc) = encoder(X_seq)\n",
    "\n",
    "    # Init beams: log_prob, Y_seq, (ht_prev, ct_prev)\n",
    "    Y_seq = torch.zeros(1, Ty).to(torch.int64)\n",
    "    Y_seq[:, 0] = Y_lexicon['<start>']\n",
    "    beams = [(0, Y_seq, (h_enc, c_enc))]\n",
    "\n",
    "    # Beam Search\n",
    "    for t in range(1, Ty):\n",
    "        new_beams = []\n",
    "        for log_prob, Y_seq, (ht_prev, ct_prev) in beams:\n",
    "            # Infer\n",
    "            with torch.no_grad():\n",
    "                # Attention\n",
    "                context = attention(\n",
    "                    enc_states=enc_out,\n",
    "                    ht_dec=ht_prev)\n",
    "\n",
    "                # Decode: yt_hat = (1, Y_lexicon_size)\n",
    "                yt_hat , ht, ct = decoder(\n",
    "                    yt_prev=Y_seq[:, t-1],\n",
    "                    context_vector=context,\n",
    "                    ht_dec=ht_prev, ct_dec=ct_prev)\n",
    "\n",
    "            # Update beams\n",
    "            top_log_probs, top_indices = yt_hat[0,:].topk(beam_width)\n",
    "            for b in range(beam_width):\n",
    "                Y_seq_b = deepcopy(Y_seq)\n",
    "                Y_seq_b[:, t] = top_indices[b].item()\n",
    "                new_beams.append((\n",
    "                    log_prob + top_log_probs[b].item(),\n",
    "                    Y_seq_b,\n",
    "                    (ht, ct)))\n",
    "        # Relax beams\n",
    "        beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:beam_width]\n",
    "\n",
    "    # Retrieve best guess Y_seq\n",
    "    output_sentence = ''\n",
    "    # skip <start>\n",
    "    for idx in beams[0][1].squeeze(dim=0).tolist()[1:]:\n",
    "        if Y_inverse_lexicon[idx] == '<end>': break\n",
    "        output_sentence += Y_inverse_lexicon[idx]\n",
    "    return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Input]                        [Prediction]    [Correct Label]\n",
      "30 jul 2010                    2010-07-30      2010-07-30     \n",
      "wednesday december 12 2001     2001-12-12      2001-12-12     \n",
      "sunday february 11 1996        1996-02-11      1996-02-11     \n",
      "sunday may 10 2015             2015-05-10      2015-05-10     \n",
      "jun 17 2018                    2018-06-17      2018-06-17     \n",
      "2 may 1974                     1974-05-02      1974-05-02     \n",
      "saturday january 21 1995       1995-01-21      1995-01-21     \n",
      "12 01 13                       2013-01-12      2013-01-12     \n",
      "20 february 1993               1993-02-20      1993-02-20     \n",
      "sunday june 11 1978            1978-06-11      1978-06-11     \n"
     ]
    }
   ],
   "source": [
    "print(f'{\"[Input]\":30} {\"[Prediction]\":15} {\"[Correct Label]\":15}')\n",
    "for i in range(10):\n",
    "    pred = infer_beam(model, X_test[i],\n",
    "        X_lexicon=X_lexicon,\n",
    "        Y_lexicon=Y_lexicon, Y_inverse_lexicon=Y_inverse_lexicon,\n",
    "        Tx=Tx, Ty=Ty)\n",
    "    print(f'{X_test[i]:30} {pred:15} {Y_test[i]:15}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 99.700%\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "Y_test_pred = Parallel(n_jobs=2)(delayed(function=infer_beam)(model, utt,\n",
    "    X_lexicon=X_lexicon,\n",
    "    Y_lexicon=Y_lexicon, Y_inverse_lexicon=Y_inverse_lexicon,\n",
    "    Tx=Tx, Ty=Ty)\n",
    "        for utt in X_test)\n",
    "\n",
    "# Acc\n",
    "scores = [ 1 if Y_test_pred[i] == Y_test[i] else 0 \\\n",
    "    for i in range(len(Y_test)) ]\n",
    "print(f'Test accuracy = {100.0*sum(scores)/len(Y_test):.3f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b166c11a6fb13fc284d60599e45a47824480cbed14934159809ec834d0d5166e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
