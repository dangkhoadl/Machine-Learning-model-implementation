{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101636\n",
      "['ive been thinking about buying new towels.', 'ive been thinking about buying new towels.', 'base jumping is an extreme sport.', 'dancing is basically a rigorous sport.', \"i don't know and i don't care.\"]\n"
     ]
    }
   ],
   "source": [
    "# Source seq\n",
    "with open('../datasets/test/en', 'r+') as file_obj:\n",
    "    data_en = file_obj.readlines()\n",
    "data_en = [ line.strip().lower() for line in data_en ]\n",
    "\n",
    "print(len(data_en))\n",
    "print(data_en[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101636\n",
      "['tôi đang nghĩ về việc mua khăn mới.', 'tôi đã suy nghĩ về việc mua khăn mới.', 'nhảy cầu là một môn thể thao mạo hiểm.', 'nhảy cơ bản là một môn thể thao khắc nghiệt.', 'tôi không biết và tôi không quan tâm.']\n"
     ]
    }
   ],
   "source": [
    "# Target seq\n",
    "with open('../datasets/test/vi', 'r+') as file_obj:\n",
    "    data_vi = file_obj.readlines()\n",
    "data_vi = [ line.strip().lower() for line in data_vi ]\n",
    "\n",
    "print(len(data_vi))\n",
    "print(data_vi[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Translate single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "## Load model\n",
    "transformer = torch.load('ckpts/8B_Transformer_en2vi.model.pth')\n",
    "transformer = transformer.to('cpu')\n",
    "transformer.eval()\n",
    "\n",
    "## Load tokenizers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "en_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'bert-base-uncased')\n",
    "vi_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'vinai/phobert-base')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b166c11a6fb13fc284d60599e45a47824480cbed14934159809ec834d0d5166e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
