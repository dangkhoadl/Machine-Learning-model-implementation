{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import Seq2SeqDataset, translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101636\n",
      "['ive been thinking about buying new towels.', 'ive been thinking about buying new towels.', 'base jumping is an extreme sport.', 'dancing is basically a rigorous sport.', \"i don't know and i don't care.\"]\n"
     ]
    }
   ],
   "source": [
    "# Source seq\n",
    "with open('../datasets/test/en', 'r+') as file_obj:\n",
    "    test_en = file_obj.readlines()\n",
    "test_en = [ line.strip().lower() for line in test_en ]\n",
    "\n",
    "print(len(test_en))\n",
    "print(test_en[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101636\n",
      "['tôi đang nghĩ về việc mua khăn mới.', 'tôi đã suy nghĩ về việc mua khăn mới.', 'nhảy cầu là một môn thể thao mạo hiểm.', 'nhảy cơ bản là một môn thể thao khắc nghiệt.', 'tôi không biết và tôi không quan tâm.']\n"
     ]
    }
   ],
   "source": [
    "# Target seq\n",
    "with open('../datasets/test/vi', 'r+') as file_obj:\n",
    "    test_vi = file_obj.readlines()\n",
    "test_vi = [ line.strip().lower() for line in test_vi ]\n",
    "\n",
    "print(len(test_vi))\n",
    "print(test_vi[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Translate single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Load model\n",
    "transformer = torch.load('ckpts/8B_Transformer_en2vi.model.pth')\n",
    "transformer = transformer.to(device)\n",
    "transformer.eval()\n",
    "\n",
    "## Load tokenizers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "en_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'bert-base-uncased')\n",
    "vi_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'vinai/phobert-base')\n",
    "\n",
    "## Load test dset\n",
    "Tx = 55\n",
    "Ty = 60\n",
    "test_dset = Seq2SeqDataset(\n",
    "    en_tokenizer=en_tokenizer, vi_tokenizer=vi_tokenizer,\n",
    "    Tx=Tx, Ty=Ty,\n",
    "    en_sentences=\"../datasets/test/en\",\n",
    "    vi_sentences=\"../datasets/test/vi\",\n",
    "    mode=\"test\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[En]: life in the city has never agreed with me.\n",
      "[Vi-Groundtruth]: cuộc sống ở thành phố chưa bao giờ đồng ý với tôi.\n",
      "\t[Vi-Translate 0]: <s> cuộc sống ở thành phố chưa bao giờ nói chuyện với tôi. </s>\n",
      "\t[Vi-Translate 1]: <s> cuộc sống ở thành phố chưa bao giờ đồng ý với tôi. </s>\n",
      "\t[Vi-Translate 2]: <s> cuộc sống ở thành phố nhưng chưa bao giờ nói chuyện với tôi. </s>\n",
      "\t[Vi-Translate 3]: <s> cuộc sống ở thành phố chưa bao giờ nói với tôi. </s>\n",
      "\t[Vi-Translate 4]: <s> cuộc sống ở thành phố chưa bao giờ đồng ý. </s>\n",
      "\t[Vi-Translate 5]: <s> cuộc sống ở thành phố chưa bao giờ quyết định. </s>\n",
      "\t[Vi-Translate 6]: <s> cuộc sống ở thành phố chưa bao giờ nói chuyện. </s>\n",
      "\t[Vi-Translate 7]: <s> cuộc sống ở thành phố chưa bao giờ quyết định với tôi. </s>\n",
      "\t[Vi-Translate 8]: <s> cuộc sống ở thành phố nhưng chưa bao giờ nói chuyện. </s>\n",
      "\t[Vi-Translate 9]: <s> cuộc sống ở thành phố chưa bao giờ nói chuyện với em. </s>\n",
      "[En]: i came to tokyo when i was three.\n",
      "[Vi-Groundtruth]: anh đến tokyo lúc ba tuổi.\n",
      "\t[Vi-Translate 0]: <s> tôi đã đến tokyo, tôi đến tom. </s>\n",
      "\t[Vi-Translate 1]: <s> tôi đã đến tokyo, tôi đến to. </s>\n",
      "\t[Vi-Translate 2]: <s> tôi đã đến tokyo, tôi đến tokyo. </s>\n",
      "\t[Vi-Translate 3]: <s> tôi đến tokyo, tôi đến to. </s>\n",
      "\t[Vi-Translate 4]: <s> tôi đến tokyo, tôi đến tom. </s>\n",
      "\t[Vi-Translate 5]: <s> tôi đã đến tokyo, tôi đến ba tuổi. </s>\n",
      "\t[Vi-Translate 6]: <s> tôi đã đến tokyo, to, tôi đến tom. </s>\n",
      "\t[Vi-Translate 7]: <s> tôi đến tokyo, tôi đã đến tom. </s>\n",
      "\t[Vi-Translate 8]: <s> tôi sẽ đến tokyo, tôi đến tom. </s>\n",
      "\t[Vi-Translate 9]: <s> tôi đã đến tokyo, to, tôi đến tokyo. </s>\n"
     ]
    }
   ],
   "source": [
    "test_size = len(test_dset)\n",
    "for i in range(2):\n",
    "    sample_idx = np.random.randint(0, test_size)\n",
    "\n",
    "    x_utt = test_dset[sample_idx]['X_sentence']\n",
    "    y_utt = test_dset[sample_idx]['Y_sentence']\n",
    "    y_decodes = translate(x_utt,\n",
    "        model=transformer,\n",
    "        en_tokenizer=en_tokenizer, vi_tokenizer=vi_tokenizer,\n",
    "        Tx=Tx, Ty=Ty, beam_width=10, device=device)\n",
    "    \n",
    "    print(f'[En]: {x_utt}')\n",
    "    print(f'[Vi-Groundtruth]: {y_utt}')\n",
    "    for x, (decode, att) in enumerate(y_decodes):\n",
    "        print(f'\\t[Vi-Translate {x}]: {decode}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:09<00:00, 18.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46462185423549635"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 20\n",
    "\n",
    "preds = []\n",
    "refs = []\n",
    "for i in tqdm(range(test_size)):\n",
    "    # Ref\n",
    "    vi_utt = test_dset[i]['Y_sentence']\n",
    "    refs.append( [['<s>'] + vi_utt.split(' ') + ['</s>']] )\n",
    "\n",
    "    # Hyp\n",
    "    en_utt = test_dset[i]['X_sentence']\n",
    "    vi_decodes = translate(en_utt,\n",
    "        model=transformer,\n",
    "        en_tokenizer=en_tokenizer, vi_tokenizer=vi_tokenizer,\n",
    "        Tx=Tx, Ty=Ty, beam_width=10, device=device)\n",
    "    preds.append( vi_decodes[0][0].split(' ') )\n",
    "\n",
    "bleu_score(preds, refs, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b166c11a6fb13fc284d60599e45a47824480cbed14934159809ec834d0d5166e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
